# Processus et threads

## Processus

### Définition

Une instance de programme qui s'exécute.

### Ordonnanceur

Responsable de choisir le processus à exécuter.

## `fork()`

Lorsque `fork()` est appelé

- Le processus se duplique
- Un processus enfant est créé
- La mémoire qui va être écrite est copiée
- Si la mémoire n'est pas écrite, le système d'exploitation va faire pointer les adresses virtuelles
vers les mêmes adresses physiques

### Exemple de `fork()`

```C
int main(void)
{
   pid_t pid = fork();

   if (pid == -1) {
      perror("fork failed");
      exit(EXIT_FAILURE);
   }
   else if (pid == 0) {
      printf("Hello from the child process!\n");
      _exit(EXIT_SUCCESS);
   }
   else {
      int status;
      (void)waitpid(pid, &status, 0);
   }
   return EXIT_SUCCESS;
}
```

```C
#include <unistd.h>
#include <sys/types.h>
#include <sys/wait.h>

int main ( int argc, char *argv[ ] ) {
    int LePid;
    LePid=fork();
    if (LePid==0) { /* fils */
        printf(“je suis le fils %d\n”,getpid());
        sleep(10); exit();
    }
    else { /* le parent seulement */
        printf(“je suis le père %d\n”,getpid());
        wait(0);
    }
}
```

## Threads

- Partage de l'espace d'adressage
    - Partager variables globales
    - Pas de protection mémoire entre thread
- Partage des ressources
- Chaque thread a sa pile
- Beaucoup plus rapide à créer qu'un processus, car moins
de ressources associées (tableau de données beaucoup plus
petit)

### Exemple de code de threads

```C
void *print_hello(void *tnum) {
    printf(“Bonjour je suis le thread %d\n”,*(int*)tnum);
    pthread_exit(NULL);
}
int main(int argc, char *argv[]) {
    // Le programme cree 10 threads et se termine
    int status, i, Arg[N_THREADS];
    for (i=0; i < N_THREADS; i++) {
        Arg[i] = i;
        printf(“Main(): en train de creer thread %d\n”,i);
        status = pthread_create(&threads[i], NULL, print_hello, (void *)&Arg[i]);
        if (status != 0) {
        printf(“oops, pthread a retourne le code d’erreur %d\n”,status);
        exit(-1);
        }
    }
    // Attendre la fin des threads
    for (i=0; i < N_THREADS; i++) { pthread_join(threads[i], NULL); }
    exit(NULL);
}
```

```C
void *print_hello(void *tnum) {
    printf(“Bonjour je suis le thread %d\n”,*(int*)tnum);
    pthread_exit(NULL);
}

int main(int argc, char *argv[]) {
    // Le programme cree 10 threads et se termine
    pthread_t threads[N_THREADS];
    int status, i, Arg[N_THREADS];
    for (i=0; i < N_THREADS; i++) {
        Arg[i] = i;
        printf(“Main(): en train de creer thread %d\n”,i);
        status = pthread_create(&threads[i], NULL, print_hello, (void *)&Arg[i]);
        if (status != 0) {
            printf(“oops, pthread a retourne le code d’erreur %d\n”,status);
            exit(-1);
        }
        pthread_join(threads[i], NULL);
    }
    exit(NULL);
}
```

### Threads utilisateurs

#### Avantages

- Plus efficace, car pas besoin de passer par le noyau

#### Désavantages

- Difficile d'implémenter parfaitement
    - Détecter les appels bloquants
        - pour occuper un autre thread pendant l'attente
    - l'idée de base des threads était de ne pas s'en faire avec les
    appels bloquants
    - Réécrire certaines fonctions systèmes avec `select()`
- Pas de préemption
    - Processus ne peut pas interrompre un thread
    - Les threads doivent coopérer

### Threads noyau

#### Avantages

- Ordonnanceur du système d'exploitation va pouvoir
    - préemption du thread en cours
    - détecter appels systèmes bloquants

## Conditions de concurrence

- Partager un système de stockage (écriture/lecture)
    - fichiers (e.g. ajouts parallèles dans un répertoire)
    - base de données
    - mémoire partagée (*shared memory*)
- Si deux processus tentent d'accéder à ce stockage partagé,
il peut y avoir des bogues subtils:
    - conditions de concurrence / *race condition*

### Spinlocks

#### Solution de Peterson

```C
int critical[2];

void enter_region(int process) {
    int other;
    other = 1 - process; // Position 1
    critical[process]=1; // Position 2
    waiting = process;
    while(waiting==process&&critical[other] == 1);
}

void leave_region(int process) {
    critical[process] = 0;
}
```

#### Test and Set Lock

```ARM
enter_region:
    TSL EAX, LOCK    | copie LOCK dans registre EAX, LOCK = 1
    CMP EAX, #0      | LOCK était-elle à 0?
    JNE enter_region | si LOCK pas à 0, boucle
    RET              | LOCK libre, entre dans section critique

leave_region:
    MOV LOCK, #0     | écrit un 0 dans LOCK
    RET              | retourne à l’appelant
```

#### XCHG

```ASM
enter_region:
    MOV EAX, #1       | copie LOCK dans registre, LOCK = EAX
    XCHG EAX, LOCK    | LOCK était-elle à 0?
    CMP EAX, #0       | si LOCK pas à 0, boucle
    JNE enter_region  | LOCK libre, entre dans section critique
    RET
leave_region:
    MOV LOCK, #0      | écrit un 0 dans LOCK
    RET               | retourne à l’appelant
```

### Sémaphores

#### POSIX

```C
sem_init()      // initialiser sémaphore sans nom
sem_open()      // ouvrir un sémaphore avec nom
sem_close()     // fermer un sémaphore avec nom
sem_unlink()    // enlever sémaphore avec nom
sem_wait()      // down
sem_post()      // up
sem_getvalue()  // valeur du sémaphore
sem_destroy()   // détruire un sémaphore créé par sem_init
```

#### Exemple d'utilisation

```C
int main(int argc, char *argv[]) {
    // Un seul sémaphore, pour le processus
    sem_t *pSemaphore = sem_open("UnNomUnique5", O_CREAT, 0644, 1);
    if (pSemaphore == SEM_FAILED) {
        return -1;
    }
    int i;
    for (i = 0; i<10; i++) {
        sem_wait(pSemaphore);
        printf("Processus %d dans la section critique\n",getpid());
        sleep(1);
        sem_post(pSemaphore);
    }
    exit(0);
}
```

## Ordonnancement

### First Come, First Served

Le premier arrivé dans la file de threads/processus est le
premier exécuté.

### Shortest Job First

Celui qui a le temps d'exécution le plus court est exécuté en
premier. Si un processus a un temps d'exécution plus court que
que les autres, mais qu'il a un temps d'arrivé qui fait qu'il 
arrive après les autres, il sera exécuté après l'exécution du
processus courant.

### Shortest Remaining Time

On prend le processus qui a le temps le plus court et on
l'effectue en premier. À chaque fois qu'un nouveau processus
arrive, on déduit le temps d'exécution qui s'est écoulé du temps
du processus actuel et on regarde si avec cette déduction, on est
mieux de changer de processus.

### Round Robin

L'ordonnanceur prend un quanta de temps (exemple: 4 ms)
et exécute le premier processus. Si celui peut encore s'exécuter
à la fin du quanta, l'ordonnanceur le place à la fin de la file
et il prend le prochain processus. Il effectue ensuite la même
étape avec le nouveau processus et ainsi de suite jusqu'à ce 
que tous les processus soient finis.

#### Taille du quanta

Il ne faut pas que le quanta soit trop petit, car, sinon, il y
aura des pertes de temps lors des fréquents changements de 
processus. Il ne faut pas non plus qu'il soit trop long, sinon
il risque d'y avoir des pertes de temps si les processus sont 
plus courts. Aussi, la réponse sera moins fluide, car les
processus seront exécutés plus longtemps individuellement.

#### File d'exécution

- 1 file **expirée**, 1 file **active**
- 1 paire par CPU
- 140 niveaux de priorités
- Petit numéro = grande priorité
- Quand toutes les tâches sont expirées, échanger les files:
**epoch** (intervertir les pointeurs des files)

### Ordonnanceurs Linux (O(1))

- Trois **policy**:
    - `SCHE_FIFO`
        - Temps réel, pas de préemption -> pas de quantum
    - `SCHED_RR`
        - Temps réel, préemption -> timeslice
    - `SCHED_NORMAL`
        - Pour les threads normaux
        - Vos processus et threads

#### `SCHED_FIFO`

**FIFO**
:   First In First Out

- Premier arrivé, premier servi
- Sans préemption, sauf si nouveau plut haute priorité
arrive (*danger boucle sans fin!*)
- Processus doit avoir les droits **superuser**

#### `SCHED_RR`

- Peuvent être préempter par `SCHED_FIFO`
- Possèdent un quantum
- Tourniquet par niveau de priorité
- Processus doit avoir les droits **superuser**

###### `SCHED_FIFO` et `SCHED_RR`

- Vont tourner tant qu'ils ont besoin de temps
- Lorsqu'ils ont tout terminé, l'ordonnanceur O(1)
commence à exécuter les threads dans `SCHED_NORMAL`

#### `SCHED_NORMAL`

##### Priorité statique

- On attribue un niveau de priorité statique $P_{statique}$
à chaque processus
- Varie entre -20 et -19
- Par défaut, $P_{statique} = 0$
- Changer $P_{statique}$ avec **nice** ou **setpriority()**
    - valeur positive -> réduire priorité
        - pour des longues simulations à tourner
    - valeur négative -> augmenter priorité
        - besoin d'être **superuser**

##### Priorité dynamique

- $P_{dynamique}$ est ajustée automatiquement par le système
d'exploitation
- Basée sur des heuristiques
- Calculé à partir du temps qu'un thread passe bloqué
    - plus il bloque longtemps, plus $P_{dynamique} augmente
- Ne s'applique pas au temps réel
    - `SCHED_FIFO`
    - `SCHED_RR`

$$
    -5 \leq P_{dynamique} \leq 5
$$

##### Niveaux de priorités

$$P_{sched} = 120 + P_{statique} + P_{dynamique}$$

où $-20 \leq P_{statique} \leq 19$ et $-5 \leq P_{dynamique} \leq +5$

- Doit rester dans la plage 100 à 139

##### Timeslice

Les processus **hautes priorités statiques** vont recevoir plus de
temps de calcul: **timeslice**

$$
    \text{Timeslice} =
    \begin{cases}
        (140 - SP) \times 20 &\text{if}~~ SP < 120 \text{(besoin superuser)} \\
        (140 - SP) \times 5  &\text{if}~~ SP \geq 120\\
    \end{cases}
$$

###### Algorithme

1. On commence par la priorité 100
2. $\forall P$:
    a. On exécute chaque processus pendant le **timeslice**
    b. Si le processu ne termine pas, préempte et transfert
    dans la file expirée, et exécute le suivant dans $P$
    c. Si $P$ est vide, on fait $P = P + 1$ (on descend)
    d. Si $P$ est à 140, la file active est vide:
        i. Intervertit la file vide avec la file expirée
        ii. $P = 100$
        iii. On recommence les étapes précédentes

###### Pourcentage de temps de processeur

Pour avoir le pourcentage de temps de processeur utilisé,
on utilise la formule suivante:

$$
    \frac{\mathrm{Timeslice}_i}{\sum\limits_{j = 1}^{N} \mathrm{Timeslice}_j}
$$

où $\mathrm{Timeslice}_i$ est le timeslice du processus dont on souhaite
avoir le pourcentage et $\sum\limits_{j = 1}^{N} \mathrm{Timeslice}_j$
est la somme des timeslices de tous les autres processus (y compris
le processus courant).

###### `sched_yield()`

- Dit au système d'exploitation qu'on veut céder son tour
- L'ordonnanceur déplace le thread appelant de la **file active**
à la **file expirée**
- Tous les autres threads seront ré-exécutés avant que l'appelant
du `sched_yield()` ne reçoive le processeur de nouveau.

#### Faiblesses

- Performe bien pour des serveurs de calcul
- Pour des ordinateurs personnels, processus interactifs souffrent
    - *IO-bound*, car ils attendent sur le clavier et la souris
- Processus de faibles priorités peuvent souffrir de famine
- Ratio entre les *timeslices* de priorité consécutives varie
grandement

### Ordonnanceur Linux (Completely Fair Scheduler ou CFS)

- Cherche à simuler un processeur parfait et offrir
$\frac{1}{N}$ du processeur aux $N$ processus...
- ... mais aussi en tenant compte de leur priorité
- Juste entre les différents utilisateurs aussi
- L'algorithme s'applique seulement à `SCHED_NORMAL`

#### Poids $w$

- Pour chaque niveau de priorité, on associe un poids $w$
- Progression géométrique, avec ratio de 1.25 entre les
valeurs de priorités consécutives

$$
    \frac{w(p - 1)}{w(p)} \approx 1.25
$$

- La fraction moyenne d'exécution désirée pour chaque
thread $i$ sera

$$
    \frac{w_i}{\sum\limits_{j = 1}^{N} w_j}
$$

où $N$ est le nombre de processus prêt à tourner

#### Période $T_{period}$

- $T_{period}$: Période pendant laquelle on voudrait 
idéalement faire tourner chacun des $N$ threads une fois
- $T_{slice}$: Temps d'exécution du thread $i$: 

$$
    T_{slice} = T_{period} \frac{w_i}{\sum\limits_{j = 1}^{N}}
$$

Idéalement, $T_{period} = 15 ~\mathrm{ms}$

#### Réalisation

- À chaque *top d'horloge* (intervalle $\Delta t = 1.4$ ou $10 ~\mathrm{ms}$),
l'ordonnanceur:
    - Ajuste le **vruntime** du processus en cours par plus $\frac{1024}{w}\Delta t$
    - Vérifie s'il a tourné plus que $T_{slice}$. Si oui, on insère
    le processus en cours dans la liste, puis on choisi le nouveau
    processus (ou thread) qui a le plus petit **vruntime** dans la
    liste triée (un *red-black tree*)
- **vruntime** va permettre de corriger, à la longue, les erreurs d'arrondi
d'exécution

#### Nouveaux processus

- Ordonnanceur lui donne le plus petit runtime de la liste:

$$
    \mathrm{vruntime}~=~\mathrm{min}(P_i.\mathrm{vruntime})
$$

- Favorise l'exécution rapide du nouveau processus

#### Processus bloqué qui se réveille

- Donner une certaine priorité au réveil: **interactivité**
- Si processus dors moins longtemps que $T_{period}$:
    - Ordonnanceur réinsère dans la file sans toucher à son
    **vruntime**

- Si processus dort plus longtemps que $T_{period}$:
    - Lui donner $\mathrm{vruntime}~=~\mathrm{min}(P_i.\mathrm{vruntime})$
    dans la file
    - A pour effet de le faire démarrer rapidement
    - Assure que son vruntime n'est pas artificiellement très faible
    (si a dormi longtemps)

#### Avoir le pourcentage de temps de processeur

Pour avoir le pourcentage de temps de processeur pour chaque
processus, on utilise la formule suivante:

$$
    \frac{w_i}{\sum\limits_{j = 1}^{N}}
$$

où $w_i$ est le poid processus dont on souhaite avoir le pourcentage
de temps de processeur et $\sum\limits_{j = 1}^{N}$ est la somme
du poid de chacun des processus (y compris celui qui est exécuté).

### Ordonnanceur Windows Vista

#### Ordonnancement Windows

- Ordonnanceur appelé lors des conditions suivantes:
    1. Bloque sur sémaphore, mutex, événement, I/O
    2. Signale un objet (sémaphore, mutex, etc.) `ReleaseMutex()`
    3. Quantum de temps a expiré
    4. Thread voit sa priorité rehaussée
